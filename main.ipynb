{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyEJAIm4Dkr2ncf28FumbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oakati/Estimating-pH-of-Solutions-Using-pH-Indicators-and-Absorbance-Spectroscopy/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "uoyjo-gaYLP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "18_saqUOAsyJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Libraries\n",
        "# Importing Libraries\n",
        "# Linear Regression is imported from the sklearn library\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# mean_squared_error and mean_absolute_error are imported from sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# mean is imported from statistics library\n",
        "from statistics import mean\n",
        "# interp1d is imported from scipy.interpolate library\n",
        "from scipy.interpolate import interp1d\n",
        "# drive is imported from google.colab library\n",
        "from google.colab import drive\n",
        "# pandas, numpy, matplotlib, seaborn, math libraries are imported\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from math import ceil, floor\n",
        "# savgol_filter is imported from scipy.signal library\n",
        "from scipy.signal import savgol_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "11_5OL5jYQX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Functions\n",
        "\n",
        "def drive_mount():\n",
        "    \"\"\"\n",
        "    Mount google drive to access the input csv file\n",
        "    \"\"\"\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def is_float(value):\n",
        "    try:\n",
        "        float(value)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "def read_csv(fid, inputFile):\n",
        "    \"\"\"\n",
        "    Read the input csv file and format the dataframe\n",
        "    pHs: list of pH values to be used in the analysis\n",
        "    \"\"\"\n",
        "    # Concatenate the file path and the file name\n",
        "    fidin = fid+\"/\"+inputFile\n",
        "    # Read the csv file as a dataframe\n",
        "    df = pd.read_csv(fidin, header=[0, 1])\n",
        "    # Create a list of tuples to be used as columns in the dataframe\n",
        "    l_tuple = []\n",
        "\n",
        "    pHs = [float(df.columns[i][0]) for i in range(len(df.columns)) if is_float(df.columns[i][0])]\n",
        "\n",
        "    for pH in pHs:\n",
        "        l_tuple.append((pH,\"X\"))\n",
        "        l_tuple.append((pH,\"Y\"))\n",
        "    # Assign the tuples as columns in the dataframe\n",
        "    df.columns = pd.MultiIndex.from_tuples(l_tuple)\n",
        "    # Replace negative values in the dataframe with 0\n",
        "    df = df.clip(lower=0)\n",
        "    return df, pHs\n",
        "\n",
        "def change_colnames(colnames):\n",
        "    \"\"\"\n",
        "    Replace the prefix 'pH ' in the column names with 'X'\n",
        "    colnames: dataframe columns\n",
        "    \"\"\"\n",
        "    colnames = colnames.str.replace('pH ', 'X')\n",
        "\n",
        "# @title ip_limits\n",
        "def ip_limits(df):\n",
        "    \"\"\"\n",
        "    This function is used to create an array of limits of the interpolated points.\n",
        "    df: DataFrame - input dataframe (not used in this function)\n",
        "    return: numpy array - array of limits of the interpolated points\n",
        "    \"\"\"\n",
        "    start = 375\n",
        "    stop = 575\n",
        "    step = 5\n",
        "    return np.arange(start,stop+1,step, dtype=float)\n",
        "\n",
        "# @title interpolation\n",
        "def interpolation(pHs, df, df_ip):\n",
        "    \"\"\"\n",
        "    This function is used to perform interpolation on the input dataframe.\n",
        "    pHs: List - list of pH values\n",
        "    df: DataFrame - input dataframe\n",
        "    df_ip: DataFrame - dataframe to hold the interpolated values\n",
        "    return: DataFrame - dataframe of interpolated values\n",
        "    \"\"\"\n",
        "    xp = df_ip.index\n",
        "    for pH in pHs:\n",
        "        x = df[pH,'X'].loc[df[pH,'Y'].notna()]\n",
        "        y = df[pH,'Y'].loc[df[pH,'Y'].notna()]\n",
        "        f = interp1d(x,y)\n",
        "        yp = f(xp)\n",
        "        df_ip[pH] = yp\n",
        "    return df_ip\n",
        "\n",
        "# @title background_correction\n",
        "def background_correction(df):\n",
        "    \"\"\"\n",
        "    This function is used to perform background correction on the input dataframe.\n",
        "    df: DataFrame - input dataframe\n",
        "    return: DataFrame - dataframe after background correction\n",
        "    \"\"\"\n",
        "    df = df.sub(df.min(axis=1), axis=0)\n",
        "    return df\n",
        "\n",
        "# @title drop_nonmonotone_wavelengths\n",
        "def drop_nonmonotone_wavelengths(df, pHs):\n",
        "    \"\"\"\n",
        "    This function is used to drop non-monotone wavelengths from the input dataframe.\n",
        "    df: DataFrame - input dataframe\n",
        "    pHs: List - list of pH values\n",
        "    return: DataFrame - dataframe after dropping non-monotone wavelengths\n",
        "    \"\"\"\n",
        "    df = df.loc[(df[pHs[1]] != 0) & (df[pHs[2]] != 0) & (df[pHs[3]] != 0) & (df[pHs[4]] != 0) & (df[pHs[5]] != 0)]\n",
        "    return df\n",
        "\n",
        "# @title normalization_by_maxVal\n",
        "def normalization_by_maxVal(df):\n",
        "    \"\"\"\n",
        "    This function is used to normalize the input dataframe by the max value.\n",
        "    df: DataFrame - input dataframe\n",
        "    return: DataFrame - dataframe after normalization\n",
        "    \"\"\"\n",
        "    df = df.div(df.max(axis=1),axis=0)\n",
        "    return df\n",
        "\n",
        "def all_lambda_combinations(l1_, l2_, df_new):\n",
        "    \"\"\"\n",
        "    This function takes three inputs:\n",
        "    l1_: Dataframe containing the maximum absorbance values at the first isosbestic point.\n",
        "    l2_: Dataframe containing the maximum absorbance values at the second isosbestic point.\n",
        "    df_new: Empty dataframe to store the mean squared error values between the two isosbestic points.\n",
        "\n",
        "    The function calculates the mean squared error between the two isosbestic points for each wavelength combination.\n",
        "    It returns the df_new dataframe with the mean squared error values.\n",
        "    \"\"\"\n",
        "    x = np.array(l2_.columns)\n",
        "    for i, rowi in l1_.iterrows():\n",
        "      for j, rowj in l2_.iterrows():\n",
        "        y = np.log10(rowj / rowi).values\n",
        "        df_new.at[i, j] = np.delete(x[0] + (y - y[0]),0)\n",
        "    return df_new\n",
        "\n",
        "def drop_inf_columns(l1, l2, inf_cols):\n",
        "    \"\"\"\n",
        "    This function takes three inputs:\n",
        "    l1: Dataframe containing the maximum absorbance values at the first isosbestic point.\n",
        "    l2: Dataframe containing the maximum absorbance values at the second isosbestic point.\n",
        "    inf_cols: List of columns with \"inf\" values that need to be dropped from the dataframes.\n",
        "\n",
        "    The function drops the specified columns from the dataframes and returns the modified dataframes.\n",
        "    \"\"\"\n",
        "    l1_ = l1.drop(inf_cols, axis=1)\n",
        "    l2_ = l2.drop(inf_cols, axis=1)\n",
        "    return l1_, l2_\n",
        "\n",
        "def drop_points_near_isosbestic(df, pHs):\n",
        "  l1 = df.loc[df[max(pHs)] == 0]\n",
        "  l2 = df.loc[df[min(pHs)] == 0]\n",
        "  return l1, l2\n",
        "def red_sensor_colors(ax, m_list):\n",
        "  for t in ax.get_xticklabels():\n",
        "    txt = t.get_text()\n",
        "    if int(txt) in m_list:\n",
        "        t.set_color('r')\n",
        "  for t in ax.get_yticklabels():\n",
        "    txt = t.get_text()\n",
        "    if int(txt) in m_list:\n",
        "        t.set_color('r')"
      ],
      "metadata": {
        "id": "xCWWLONNBmUU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "Y5a5PDZ6YTzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path where the input csv file is located\n",
        "fid = \"/content/drive/My Drive/boun/5_1boun/EE492/indicator_data/pool\"\n",
        "\n",
        "# Define the name of the input csv file\n",
        "inputFile = \"sp_data.csv\"\n",
        "drive_mount()\n",
        "\n",
        "# Read in data from CSV file\n",
        "df, pHs = read_csv(fid, inputFile)\n",
        "\n",
        "# Interpolate data\n",
        "df_ip = pd.DataFrame(index=ip_limits(df),columns=pHs)\n",
        "df_ip = interpolation(pHs, df, df_ip)\n",
        "\n",
        "# Perform background correction\n",
        "df_bc = background_correction(df_ip)\n",
        "\n",
        "# Normalize data by max value\n",
        "df_nm = normalization_by_maxVal(df_bc)\n",
        "\n",
        "# Remove points near isosbestic points\n",
        "l1, l2 = drop_points_near_isosbestic(df_nm, pHs)\n",
        "\n",
        "#Create an empty dataframe with columns from l2 and index from l1\n",
        "df_hm = pd.DataFrame(columns=l2.index.values.astype(int), index=l1.index.values.astype(int))\n",
        "\n",
        "#Remove infinite values from l1 and l2 and store the result in l1_ and l2_\n",
        "l1_, l2_ = drop_inf_columns(l1, l2, [min(pHs), max(pHs)])"
      ],
      "metadata": {
        "id": "HVRltDUzBVkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47262c4e-457c-4799-c68f-0d5caf1cc380"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate all combinations of lambda values for each pH\n",
        "df_hm = all_lambda_combinations(l1_, l2_, df_hm)\n",
        "\n",
        "#filter the dataframe to only include specific wavelengths, and select every fifth index\n",
        "df_hm = df_hm.astype(float)\n",
        "\n",
        "# Take the mean as the final estimate\n",
        "df_hm.mean().mean()\n",
        "\n",
        "#Reference to the estimation method\n",
        "# https://chemlab.truman.edu/files/2015/07/pka1.pdf"
      ],
      "metadata": {
        "id": "GXopu3r4lNOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7909498c-53d7-47bd-f95b-a0646b4e18be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.113650948714234"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}